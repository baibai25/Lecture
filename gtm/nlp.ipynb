{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import ngram\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "エレキベースのスラップ奏法を対象としたスペクトル特徴と演奏制約を利用した音高・奏法推定あらまし本論文では，エレキベースの奏法の違いによる音高の推定精度の低下を改善するために，特殊な奏法の一つであるスラップ奏法を対象にスペクトル特徴と演奏制約を導入し，ネットワークの最短経路を求めることで音高と奏法を推定する手法を提案する．キーワードエレキベース，調波打楽器音分離，スラップ奏法，非負値行列因子分解１．まえがき近年，計算機を用いて音楽信号から自動で楽譜を作成する自動採譜に関する研究が盛んに行われている［１］．自動採譜システムの実現のためには，楽曲の調やコードと関連が強いベースラインの推定が重要となる\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "f = open('./data/j101-d_11_1499.txt', encoding='shift-jis')\n",
    "line = f.read()\n",
    "f.close()\n",
    "print(line[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number is 5960\n",
      "Total kind of character is 450\n"
     ]
    }
   ],
   "source": [
    "# Q1\n",
    "print('Total number is', len(line))\n",
    "print('Total kind of character is', len(collections.Counter(line)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記プログラムより、延べ文字数5960文字、文字種は450文字である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H0 = 8.813781191217037\n"
     ]
    }
   ],
   "source": [
    "# Q2\n",
    "print('H0 =', np.log2(len(collections.Counter(line))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([20, 35, 17, 21, 71, 81, 255, 28, 65, 35, 129, 79, 153, 22, 2, 132, 111, 80, 17, 48, 80, 29, 22, 14, 64, 22, 22, 4, 27, 108, 50, 3, 30, 41, 29, 29, 22, 5, 4, 6, 87, 48, 181, 20, 57, 132, 31, 174, 7, 34, 9, 5, 1, 1, 96, 22, 1, 51, 6, 14, 12, 13, 13, 20, 16, 5, 4, 4, 8, 43, 17, 10, 10, 116, 16, 11, 22, 6, 24, 10, 20, 18, 2, 2, 12, 6, 3, 5, 3, 9, 52, 9, 79, 23, 4, 1, 10, 11, 1, 70, 6, 13, 20, 4, 19, 6, 4, 14, 4, 13, 1, 1, 1, 2, 14, 36, 12, 12, 5, 3, 30, 12, 2, 8, 11, 18, 7, 6, 16, 13, 6, 1, 45, 2, 2, 5, 7, 29, 1, 1, 24, 14, 3, 5, 12, 7, 8, 1, 1, 9, 7, 8, 16, 5, 5, 3, 17, 34, 8, 22, 12, 6, 7, 12, 11, 3, 3, 11, 25, 4, 4, 3, 5, 11, 11, 30, 12, 15, 17, 4, 8, 52, 61, 10, 3, 8, 3, 14, 26, 12, 9, 6, 10, 1, 4, 4, 3, 9, 9, 19, 52, 13, 2, 6, 18, 9, 11, 15, 7, 1, 15, 2, 2, 3, 7, 2, 9, 12, 19, 12, 3, 4, 1, 1, 1, 1, 23, 5, 6, 2, 4, 30, 1, 2, 22, 12, 22, 28, 1, 1, 5, 1, 1, 5, 4, 2, 24, 6, 4, 10, 3, 5, 2, 4, 8, 2, 2, 1, 1, 1, 1, 5, 2, 5, 2, 7, 16, 5, 5, 2, 2, 5, 1, 1, 2, 1, 5, 5, 5, 2, 18, 3, 2, 7, 12, 4, 4, 4, 2, 9, 9, 2, 6, 3, 1, 2, 1, 3, 8, 7, 9, 9, 17, 5, 2, 1, 5, 7, 6, 2, 2, 2, 2, 8, 2, 5, 2, 14, 1, 2, 6, 3, 2, 5, 1, 1, 2, 7, 4, 6, 2, 3, 3, 4, 3, 2, 2, 1, 2, 1, 3, 6, 10, 1, 3, 2, 16, 23, 12, 8, 4, 4, 1, 11, 2, 3, 8, 4, 2, 1, 14, 3, 5, 1, 7, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 5, 2, 2, 1, 1, 1, 8, 5, 8, 4, 13, 14, 1, 7, 2, 1, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 3, 3, 1, 1, 1, 1, 5, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = collections.Counter(line)\n",
    "freq = np.array(list(cnt.values()))\n",
    "cnt.values() # words frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 = 7.459371410966394\n",
      "Information gain: H0-H1 = 1.3544097802506432\n"
     ]
    }
   ],
   "source": [
    "h1 = 0\n",
    "for i in range(len(freq)):\n",
    "    h1 += (freq[i]/len(line)) * np.log2(freq[i]/len(line))\n",
    "h1 *=  -1\n",
    "print('H1 =', h1)\n",
    "print('Information gain: H0-H1 =', np.log2(len(collections.Counter(line)))-h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 全ての文字種が等確率で出現すると仮定した場合、文字種が450であることから、エントロピーは以下の式で求めることができる。\n",
    "\n",
    "$$\n",
    "H_0 = \\log_2 450 \\\\\n",
    "H_0 = 8.813781191217037\n",
    "$$\n",
    "\n",
    "(b) 文字の出現頻度を考慮した際のエントロピーは以下の通りである。\n",
    "$$\n",
    "H_1 = -\\frac{20}{5960} -\\log_2 \\frac{20}{5960} -\\frac{35}{5960} -\\log_2 \\frac{35}{5960} ... =7.459371410966394\n",
    "$$\n",
    "\n",
    "(c) 以上の結果より、Information gain (IG)は\n",
    "$$\n",
    "IG = H_0 - H_1 = 1.3544097802506432\n",
    "$$\n",
    "となり、約1.35[bit]である。\n",
    "\n",
    "情報エントロピーは、事前に知っていることが多いほど情報量は少なくなる。言い換えれば、不確実性が少なければ情報量も少なくなる。そのため、出現頻度を考慮したH<sub>1</sub>が、H<sub>0</sub>よりも不確実性が低いと言える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729000000 byte\n"
     ]
    }
   ],
   "source": [
    "# Q3\n",
    "# (value of kind of characters * 2byte)^3 \n",
    "print((len(collections.Counter(line))*2)**3, 'byte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3150 byte\n"
     ]
    }
   ],
   "source": [
    "# 2l+4l+l=7l \n",
    "# 7l * text size memmory must be reserbed\n",
    "print(7 * len(collections.Counter(line)), 'byte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 全文字種類は450文字であり、これらは全て全角2 byteからなる。これらの文字に対してtri-gramを適用することを考慮した場合必要となる容量は以下のとおりである。\n",
    "$$\n",
    "(450 \\times 2)^3 = 729000000 [bytes]\n",
    "$$\n",
    "\n",
    "(b) Nagaoらの手法では、text string(2l byte), pointer table(4l bytes), table of coincidence number of characters(1l byte)の計7l bytesが必要となる。このことから、(a)と同様に、全文字種類についてtri-gramを適用すると\n",
    "$$\n",
    "7 \\times 450 = 3150 [bytes]\n",
    "$$\n",
    "となり、3150 bytesのメモリを確保する必要がある。\n",
    "\n",
    "(c) 以上の結果から、Nagaoらの手法を用いることで、確保するメモリ容量を大幅に削減できることが分かる。通常のN-gramではNの数が大きくなればなるほど、容量は大きくなるが、Nagaoらの手法では、ポインターを用いて参照を行うため、大規模なN-gramであっても容量の削減が期待できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$$$$$エ',\n",
       " '$$$$エレ',\n",
       " '$$$エレキ',\n",
       " '$$エレキベ',\n",
       " '$エレキベー',\n",
       " 'エレキベース',\n",
       " 'レキベースの',\n",
       " 'キベースのス',\n",
       " 'ベースのスラ',\n",
       " 'ースのスラッ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create n-gram\n",
    "index = ngram.NGram(N=6)\n",
    "ngram = []\n",
    "\n",
    "for term in index.ngrams(index.pad(line)):\n",
    "    ngram.append(term)\n",
    "ngram[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('エ', 'レ', 'キ', 'ベ', 'ー', 'ス') 16\n",
      "('ス', 'ラ', 'ッ', 'プ', '奏', '法') 17\n"
     ]
    }
   ],
   "source": [
    "dictionary = dict()\n",
    "lcw = []\n",
    "\n",
    "for s1, s2, s3, s4, s5, s6 in ngram:\n",
    "    dictionary[(s1, s2, s3, s4, s5, s6)] = dictionary.get((s1, s2, s3, s4, s5, s6),0)+1\n",
    "    \n",
    "for i in range(len(dictionary)):\n",
    "    if list(dictionary.values())[i] > 15:\n",
    "        lcw.append(list(dictionary)[i])\n",
    "        print(list(dictionary)[i], list(dictionary.values())[i])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プログラムより、閾値15かつ、6文字以上を満たす the longest compound wordとして、以下の2つが抽出された。\n",
    "\n",
    "+ エレキベース (16)\n",
    "+ スラップ奏法 (17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['エ', 'エレ', 'エレキ', 'エレキベ', 'エレキベー', 'ス', 'スラ', 'スラッ', 'スラップ', 'スラップ奏']\n",
      "['レキベース', 'キベース', 'ベース', 'ース', 'ス', 'ラップ奏法', 'ップ奏法', 'プ奏法', '奏法', '法']\n"
     ]
    }
   ],
   "source": [
    "# split word to w1 and w2\n",
    "w1, w2 = [], []\n",
    "\n",
    "for i in range(len(lcw)):\n",
    "    word = ''.join(lcw[i])\n",
    "    \n",
    "    for j in range(len(word)-1):\n",
    "        #print(word[:j+1], word[j+1:])\n",
    "        w1.append(word[:j+1])\n",
    "        w2.append(word[j+1:])\n",
    "print(w1)\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count freq of w1 and w2\n",
    "w1_freq = []\n",
    "w2_freq = []\n",
    "w_sum = []\n",
    "\n",
    "for i in range(len(w1)):\n",
    "    w1_freq.append(line.count(w1[i]))\n",
    "    w2_freq.append(line.count(w2[i]))\n",
    "    w_sum.append(line.count(w1[i]) + line.count(w2[i]))\n",
    "    \n",
    "df = pd.DataFrame([w1, w1_freq, w2, w2_freq, w_sum]).T\n",
    "df.columns = ['w1', 'w1 frequency', 'w2', 'w2 frequency', 'sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下が分割したw1, w2とそれぞれの出現頻度をまとめた表である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w1 frequency</th>\n",
       "      <th>w2</th>\n",
       "      <th>w2 frequency</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>エ</td>\n",
       "      <td>20</td>\n",
       "      <td>レキベース</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>エレ</td>\n",
       "      <td>16</td>\n",
       "      <td>キベース</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>エレキ</td>\n",
       "      <td>16</td>\n",
       "      <td>ベース</td>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>エレキベ</td>\n",
       "      <td>16</td>\n",
       "      <td>ース</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>エレキベー</td>\n",
       "      <td>16</td>\n",
       "      <td>ス</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ス</td>\n",
       "      <td>81</td>\n",
       "      <td>ラップ奏法</td>\n",
       "      <td>17</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>スラ</td>\n",
       "      <td>18</td>\n",
       "      <td>ップ奏法</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>スラッ</td>\n",
       "      <td>17</td>\n",
       "      <td>プ奏法</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>スラップ</td>\n",
       "      <td>17</td>\n",
       "      <td>奏法</td>\n",
       "      <td>65</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>スラップ奏</td>\n",
       "      <td>17</td>\n",
       "      <td>法</td>\n",
       "      <td>79</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      w1 w1 frequency     w2 w2 frequency sum\n",
       "0      エ           20  レキベース           16  36\n",
       "1     エレ           16   キベース           16  32\n",
       "2    エレキ           16    ベース           19  35\n",
       "3   エレキベ           16     ース           24  40\n",
       "4  エレキベー           16      ス           81  97\n",
       "5      ス           81  ラップ奏法           17  98\n",
       "6     スラ           18   ップ奏法           17  35\n",
       "7    スラッ           17    プ奏法           17  34\n",
       "8   スラップ           17     奏法           65  82\n",
       "9  スラップ奏           17      法           79  96"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　頻度の合計が最も大きくなった組み合わせは ['エレキベー'(16), 'ス'(81)], ['ス'(81), 'ラップ奏法'(17)] であった。適当な分割として、妥当に思えるw<sub>1</sub>とw<sub>2</sub>は、['エレキ'(16), 'ベース'(19)], ['スラップ'(17), '奏法'(65)] である。  \n",
    "　文字数が小さいほど、文中で登場する回数は多くなる可能性が高く、今回このような結果を得たのもこれが理由であると考えられる。実際に、['エ', 'レキベース'], ['エレキベー', 'ス'], ['ス', 'ラップ奏法'], ['スラップ奏', '法']のように、1文字のみになる分割を行った際の頻度が高くなっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
